1. I think the idea of including UI in this will make the code monolithic.
2. This should most probably be a library.
3. So, what should be our UI.
4. If we need a UI there are other UI libraries or tools.
5. But how to integrate the UI features in the library with others.
6. We will have to fix on the expectations from the library.
7. More specifically we will have to have a fix on the rendering.
8. Consider the web UI's already visited based on virtul humans.
9. Let's think how their system could have organized.
10. The input will be accepted and will be passed to core library. The result will be paased to the virtual human avatar.
11. There is 3 separate modules here. Input related, core process related, and virtual human.
12. Inputs can be mic, keyboard, camera etc.
13. Core process will process inputs.
14. Outputs can be something related to graphics, speaker, etc.
15. Graphics is atleast for me a bit hard to implement due to lack of expertise.
16. So, it is relatively easy to implement other.
17. The whole process is event driven.
18. Why is it event driven?
19. Let's see, what exactly is event driven design is?
20. Event driven design works, but it's already in most of the libraries. May be we can wrap it around.
21. We need a global visualisation and each of its technical counterpart.
22. Let's list them.
23. Use clicks on the icon. A window will be opened. Inside that window, there will be the character we will be creating. The character should be introduced in a realistic way. Once the user-character contact is established, the character should be able to communicate in a reliable way. Most preferably like in a video call.
24. I paused the above process. I am spending some time on agile. I just want to wet my thoughts. This is to make sure that I am not falling for my own error.
